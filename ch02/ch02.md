### 2.1.2 安装Java

 - 推荐安装Java8

### 2.1.3 安装zookeeper

**1. 单机模式**

 - 去官网下载，然后执行以下的指令：
```
# tar -zxf apache-zookeeper-3.6.2-bin.tar.gz
# mv apache-zookeeper-3.6.2-bin /usr/local/zookeeper
# mkdir -p /var/lib/zookeeper
# cat > /usr/local/zookeeper/conf/zoo.cfg << EOF
> tickTime=2000
> dataDir=/var/lib/zookeeper
> clientPort=2181
> EOF
# /usr/local/zookeeper/bin/zkServer.sh start
(可能需要用sudo)
```

zookeeper文件包含有bin，conf，lib等目录：
 - bin目录中存放有运行脚本；
 - conf目录中存放有配置文件；
 - lib目录中存放有运行所需要第三方库。

```
## 启动ZooKeeper
./bin/zkServer.sh start
## 停止ZooKeeper
./bin/zkServer.sh stop
```

**2. ZooKeeper群组（Ensemble）**

 - ZooKeeper集群被称为**群组**。
 - 建议每个群组应该包含奇数的节点（如3、5个），因为只有当群组里的大多数节点处于可用状态，Zookeeper才能处理外部的请求。
 - 群组需要有一些公共配置，并且每个服务器还要在数据目录中创建一个myid文件，由于指明自己的ID。
 - 如果群组里服务器的机器名是zoo1.example.com，zoo2.example.com，zoo3.example.com，那么配置文件是这样的：
```
tickTime=2000
dataDir=/var/lib/zookeeper
clientPort=2181
initLimit=50
syncLimit=5
server.1=zoo1.example.com
server.2=zoo2.example.com
server.3=zoo3.example.com
```
 - initLimit：从节点与主点之间建立初始化链接的时间上线
 - syncLimit：允许从节点与主节点处于不同步状态的时间上线
 - 这两个都是tickTime的倍数；eg. `initLimit = tickTime * SOME_VALUE`
 - 配置里列出的服务器地址要遵循`server.X=hostname:peerPort:leaderPort`
   - X：服务器的ID，必须是整数；不一定从0开始，也不需要连续。
   - hostname：服务器的机器名或IP地址
   - peerPort：由于节点通信的TCP端口
   - leaderPort：用于首领导的TCP端口

### 2.2 安装Kafka Broker
 - 去官网下载，下载后执行以下的指令：
```
tar -zxf kafka-2.7.0-src.tgz 
sudo mv kafka-2.7.0-src /usr/local/kafka
sudo /usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties
```

 - 如果没有Scala，需要下载；在kafka文件包理执行：
```
./gradlew jar -PscalaVersion=2.13.3 (or follow terminal's instructions)
```

**创建并验证主题**

```
# /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
Created topic "test".
# /usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test
Topic: test	PartitionCount: 1	ReplicationFactor: 1	Configs: 
	Topic: test	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
```

**往测试主题发布消息**

```
# /usr/local/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
> Test Message 1
> Test Message 2
^D
#
```

**从测试主题上读取消息**

```
# /usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
Test Message 1
Test Message 2
^C
Consumed 2 messages

(if not work, try below)
# /usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
```

## 2.3 broker配置

 - 默认的配置无法满足大多数安装场景，以下是经常需要修改的配置：

**1. broker.id**
 - 每个broker都需要一个标识符，使用broker.id来表示。
 - 默认值是0，但可设置为任何整数，只要是唯一的即可。
 - 建议设置与机器名具有相关的整数，比如：
```
host1.example.com --> server1
host2.example.com --> server2
```

**2. port**
 - 默认9092端口
 - 如果使用1024以下，需要使用root权限；因此不建议

**3. zookeeper.connect**
 - 用于指定保存broker元数据的ZooKeeper地址
 - 该配置参数是用冒号（semicolor；）分隔的一组`hostname:port/path`列表
   - hostname = zookeeper服务器的机器名或IP地址
   - port = Zookeeper的客户端端口
   - /path = 可选的zookeeper路径，作为kafka集群的chroot环境；如果不定义，默认使用根路径。
     - 如果chroot路径不存在，broker会在启动时候创建他

**为什么使用chroot路径**

 - 使用chroot路径是一种最佳实践（best practice）
 - zookeeper群组可以共享给其他应用程序，即使还有其他kafka集群存在，也不会产生冲突
 - 最好是在配置文件里指定一组Zookeeper服务器，用分号把他们隔离。
 - 一旦有一个zookeeper服务器宕机，broker可以连接到zookeeper集群的另一个节点上。

**4. log.dirs**

 - 指定消息该存放在磁盘的哪个位子
 - 是一组用逗号分隔的路径
 - 如果指定多个路径，broker会根据"**最少使用**"原则，把同一个分区的日记片段保存到同一个路径下。
   - 注意： 最少使用的意思不是拥有最小磁盘空间的路径，而是拥有最少分区数量的路径。

**5. num.recovery.threads.per.data.dir**

 - 对于如下3个种情况，Kafka会使用可配置的线程池处理日记片段：
   - 服务器正常启动，用于打开每个分区的日志片段
   - 服务器奔溃后重启，用于检查和截短每个分区的日志
   - 服务器正常关闭，用于关闭日志（log）片段

 - 注意：所配置的数字对应的是log.dirs指定的单个日志目录（如果num.recovery.threads.per.data.dir为8，而且log.dir指定了3个路径，那么总共需要24个线程）
 - 默认值是1（每个日志目录使用一个线程）
 - 因为这些线程只是在服务器启动和关闭时才会用到，所以完全可以设置大量的线程达到并行操作的目的（一旦发生崩溃，使用并行操作可以剩下数小时的时间）

**6. auto.create.topics.enable**

 - 如果设为true（默认也是true），kafka会在以下种情况自动创建主题：
   - 当一个生产者开始往主题写入消息时；
   - 当一个消费者开始从主题读取小时时；
   - 当任意一个客户端向主题发送元数据请求时
  
 - 但不建议，因为很多时候，这些行为都是非预期的。

### 2.3.2 主题的默认配置

**1. num.partitions**

 - 该参数指定了新创建的主题将包含多少个分区
 - 如果启动了主题自动创建功能（该功能默认是启动的），主题分区的个数就是该参数指定的值。
 - 该参数默认是1
 - 注意：我们可以增加主题分区的个数，但不能减少。

**2. log.retention.ms**

 - 该参数定义数据可以被保留多久
 - 默认使用`log.retention.hours`参数来配置时间，默认168小时（一周）
 - 还有两个参数`log.retention.minutes`和`log.retention.ms`；这三个参数的作用是一样的
 - 如果不只一个参数，Kafka会优先选择最小值的那个参数

**3. log.retention.bytes**

 - 通过字节数来判断消息是否过期
 - 如果同时指定了`log.retention.bytes`和`log.retention.ms`，只要任意一个条件得到满足，消息就会被删除

**4. log.segment.bytes**

 - 该参数定义了每个日志片段的大小
 - 当消息达到broker时，他们被追加到分区的当前日志片段上。
 - 当日志片段大小达到`log.segment.bytes`指定的上限（默认1GB）时，当前日志片段就会关闭，一个新的日志片段被打开。
 - 如果日志片段被关闭，就开始等待时间（log.retention.ms的计算/比较开始）
 - 该参数的值越小，就会越频繁地关闭和分配新文件，从而**降低磁盘写入的整体效率**

 - 注意：假设每天都接收100MB的消息，那么需要10天才能填满1GB（1000MB）的日志片段。由于**日志片段被关闭之前不会开始计算过期**，所以如果`log.retention.ms=604 800 000`(7天），那么日志片段最多需要17天（10+7)才会过期。

**5. log.segment.ms**

 - 该参数定义了日志片段关闭时间。
 - 默认没有设定值，所以根据大小来关闭日志片段
 - 如果分区的日志片段都达不到`log.segment.bytes`上限，那就会按照`log.segment.ms`关闭片段；但由于同时可能会有很多分区在同一个时间关闭片段并写入磁盘，所以我们也要考虑对磁盘的影响

**6. message.max.bytes**

 - broker通过该参数限制单个消息压缩后的大小，默认值是1 000 000（1MB）
 - 如果生产者发送的压缩消息超过这个大小，不仅消息不会被接收，broker还会返回错误消息。
 - 这个值越大，网络链接，线程和磁盘处理单个消息的时间就越长，从而影响吞吐量。
 - 注意：必须与参数`fetch.message.max.bytes`（消费者获取消息的大小）和参数`replica.fetch. max.bytes`（broker之间replicate消息的大小）调协；如过`message.max.bytes`大于以上的参数，那么消费者就无法获取消息，broker之间也无法。

## 2.4 硬件的选择

 - 需要考虑到磁盘吞吐量和容量，内存，网络和CPU

### 2.4.1 磁盘吞吐量

 - 生产者生成的消息必须被提交到服务器保存，大多数客户端在发送消息之后会一值等待，知道至少一个服务器确认消息已经成功提交为止。
   - 也就是说，磁盘写入越块，生成消息的延时就越低。

 - 选HDD还是SSD？SSD的查找和访问比较块，但由于HDD比较便宜所以可以比较大的容量。
 - 其他技术（比如SATA和磁盘质量）也是要考虑的因素

### 2.4.2 磁盘容量

 - 需要多大的容量取决于需要保留的信息数量
 - 如果服务器每天会收到1TB消息，并且保留7天，那就需要7TB的存储空间；而且还要为其他文件提供至少10%的额外空间
 - 提供缓冲区和复制策略也需要容量；缓冲区用于应付消息增长和波动
 - 也要考虑扩展kafka集群时，集群总容量根据分区数量能否被均衡到整个集群？
   - 如果单个broker无法撑全部容量，可以让其他broker提供可用的容量 (TODO: so does this mean broker can borrow storage from another broker? Or simply just store it in another broker?)

### 2.4.3 内存

 - 影响消费者
 - 消费者一般从分区尾部读取消息，如果生产者存在，就紧跟着生产者后面，直接读取缓存理的消息（不需要从磁盘上重新读取）
 - 运行Kafka的JVM不需要太多内存，剩余的都可以用作页面缓存，或者当前的日志片段。

### 2.4.4 网络

 - 越快越好；瓜分网络流量到多个消费者
 - 集群复制和镜像也用网络流量

### 2.4.5 CPU

 - 要求较低

## 2.5 云端的Kafka

 - skip

## 2.6 Kafka集群

 - 






